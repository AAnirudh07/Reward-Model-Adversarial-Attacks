{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "1. Install Dependencies"
      ],
      "metadata": {
        "id": "pep10KJ56zU4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "7WLA6_b66tWX",
        "outputId": "5f3c06f8-049e-453e-eb15-a6513dc733ce"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ftfy\n",
            "  Downloading ftfy-6.3.1-py3-none-any.whl.metadata (7.3 kB)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.11/dist-packages (2024.11.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (4.67.1)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.11/dist-packages (from ftfy) (0.2.13)\n",
            "Downloading ftfy-6.3.1-py3-none-any.whl (44 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.8/44.8 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: ftfy\n",
            "Successfully installed ftfy-6.3.1\n",
            "Collecting git+https://github.com/openai/CLIP.git\n",
            "  Cloning https://github.com/openai/CLIP.git to /tmp/pip-req-build-w_h8sd0t\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/openai/CLIP.git /tmp/pip-req-build-w_h8sd0t\n",
            "  Resolved https://github.com/openai/CLIP.git to commit dcba3cb2e2827b402d2701e7e1c7d9fed8a20ef1\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: ftfy in /usr/local/lib/python3.11/dist-packages (from clip==1.0) (6.3.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from clip==1.0) (24.2)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.11/dist-packages (from clip==1.0) (2024.11.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from clip==1.0) (4.67.1)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (from clip==1.0) (2.5.1+cu124)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (from clip==1.0) (0.20.1+cu124)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.11/dist-packages (from ftfy->clip==1.0) (0.2.13)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch->clip==1.0) (3.17.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch->clip==1.0) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch->clip==1.0) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch->clip==1.0) (3.1.5)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch->clip==1.0) (2024.10.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch->clip==1.0)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch->clip==1.0)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch->clip==1.0)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch->clip==1.0)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch->clip==1.0)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch->clip==1.0)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch->clip==1.0)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch->clip==1.0)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch->clip==1.0)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch->clip==1.0) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->clip==1.0) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch->clip==1.0)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch->clip==1.0) (3.1.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch->clip==1.0) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch->clip==1.0) (1.3.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchvision->clip==1.0) (1.26.4)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision->clip==1.0) (11.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch->clip==1.0) (3.0.2)\n",
            "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m95.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m70.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m56.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m11.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m73.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: clip\n",
            "  Building wheel for clip (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for clip: filename=clip-1.0-py3-none-any.whl size=1369489 sha256=32e0c26960c83dc1c4408d7aacf5c17fd277266cdc7e8f20a5388b8a6ff793a1\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-12soaz7i/wheels/3f/7c/a4/9b490845988bf7a4db33674d52f709f088f64392063872eb9a\n",
            "Successfully built clip\n",
            "Installing collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, clip\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed clip-1.0 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127\n",
            "Collecting hpsv2\n",
            "  Downloading hpsv2-1.2.0-py3-none-any.whl.metadata (17 kB)\n",
            "Requirement already satisfied: torch>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from hpsv2) (2.5.1+cu124)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (from hpsv2) (0.20.1+cu124)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.11/dist-packages (from hpsv2) (2024.11.6)\n",
            "Requirement already satisfied: ftfy in /usr/local/lib/python3.11/dist-packages (from hpsv2) (6.3.1)\n",
            "Requirement already satisfied: einops in /usr/local/lib/python3.11/dist-packages (from hpsv2) (0.8.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from hpsv2) (2.2.2)\n",
            "Collecting braceexpand (from hpsv2)\n",
            "  Downloading braceexpand-0.1.7-py2.py3-none-any.whl.metadata (3.0 kB)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from hpsv2) (2024.10.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from hpsv2) (4.67.1)\n",
            "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.11/dist-packages (from hpsv2) (0.28.1)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.11/dist-packages (from hpsv2) (0.2.0)\n",
            "Collecting protobuf<4 (from hpsv2)\n",
            "  Downloading protobuf-3.20.3-py2.py3-none-any.whl.metadata (720 bytes)\n",
            "Requirement already satisfied: timm in /usr/local/lib/python3.11/dist-packages (from hpsv2) (1.0.15)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (from hpsv2) (4.48.3)\n",
            "Collecting webdataset (from hpsv2)\n",
            "  Downloading webdataset-0.2.111-py3-none-any.whl.metadata (15 kB)\n",
            "Requirement already satisfied: pyarrow in /usr/local/lib/python3.11/dist-packages (from hpsv2) (18.1.0)\n",
            "Collecting pytest-split==0.8.0 (from hpsv2)\n",
            "  Downloading pytest_split-0.8.0-py3-none-any.whl.metadata (9.4 kB)\n",
            "Collecting pytest==7.2.0 (from hpsv2)\n",
            "  Downloading pytest-7.2.0-py3-none-any.whl.metadata (7.8 kB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from hpsv2) (2.32.3)\n",
            "Collecting clint (from hpsv2)\n",
            "  Downloading clint-0.5.1.tar.gz (29 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: attrs>=19.2.0 in /usr/local/lib/python3.11/dist-packages (from pytest==7.2.0->hpsv2) (25.1.0)\n",
            "Requirement already satisfied: iniconfig in /usr/local/lib/python3.11/dist-packages (from pytest==7.2.0->hpsv2) (2.0.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from pytest==7.2.0->hpsv2) (24.2)\n",
            "Requirement already satisfied: pluggy<2.0,>=0.12 in /usr/local/lib/python3.11/dist-packages (from pytest==7.2.0->hpsv2) (1.5.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=1.9.0->hpsv2) (3.17.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9.0->hpsv2) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.9.0->hpsv2) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9.0->hpsv2) (3.1.5)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9.0->hpsv2) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9.0->hpsv2) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9.0->hpsv2) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9.0->hpsv2) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9.0->hpsv2) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9.0->hpsv2) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9.0->hpsv2) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9.0->hpsv2) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9.0->hpsv2) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9.0->hpsv2) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9.0->hpsv2) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9.0->hpsv2) (12.4.127)\n",
            "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9.0->hpsv2) (3.1.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9.0->hpsv2) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.9.0->hpsv2) (1.3.0)\n",
            "Collecting args (from clint->hpsv2)\n",
            "  Downloading args-0.1.0.tar.gz (3.0 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.11/dist-packages (from ftfy->hpsv2) (0.2.13)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub->hpsv2) (6.0.2)\n",
            "Requirement already satisfied: numpy>=1.23.2 in /usr/local/lib/python3.11/dist-packages (from pandas->hpsv2) (1.26.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->hpsv2) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->hpsv2) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->hpsv2) (2025.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->hpsv2) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->hpsv2) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->hpsv2) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->hpsv2) (2025.1.31)\n",
            "Requirement already satisfied: safetensors in /usr/local/lib/python3.11/dist-packages (from timm->hpsv2) (0.5.3)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision->hpsv2) (11.1.0)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers->hpsv2) (0.21.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->hpsv2) (1.17.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.9.0->hpsv2) (3.0.2)\n",
            "Downloading hpsv2-1.2.0-py3-none-any.whl (7.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.7/7.7 MB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pytest-7.2.0-py3-none-any.whl (316 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m316.8/316.8 kB\u001b[0m \u001b[31m32.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pytest_split-0.8.0-py3-none-any.whl (11 kB)\n",
            "Downloading protobuf-3.20.3-py2.py3-none-any.whl (162 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m162.1/162.1 kB\u001b[0m \u001b[31m21.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading braceexpand-0.1.7-py2.py3-none-any.whl (5.9 kB)\n",
            "Downloading webdataset-0.2.111-py3-none-any.whl (85 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.5/85.5 kB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: clint, args\n",
            "  Building wheel for clint (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for clint: filename=clint-0.5.1-py3-none-any.whl size=34459 sha256=231000c5880e6222e32dd2ae0374b3173987f74754326a2b7de1505f47f3d3b9\n",
            "  Stored in directory: /root/.cache/pip/wheels/a0/8d/f3/91dd49f9a8c6a57be7715f6d11347c49971dd292a53397ed79\n",
            "  Building wheel for args (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for args: filename=args-0.1.0-py3-none-any.whl size=3319 sha256=3cd9735f5ba42875c6cbe523d53542f0c473f11de38e0fc4975c70a403e0d643\n",
            "  Stored in directory: /root/.cache/pip/wheels/15/a2/87/2541eb895fd18fd20cc7dd18b14d3b61bd9084cf4322abd15e\n",
            "Successfully built clint args\n",
            "Installing collected packages: braceexpand, args, webdataset, pytest, protobuf, clint, pytest-split, hpsv2\n",
            "  Attempting uninstall: pytest\n",
            "    Found existing installation: pytest 8.3.4\n",
            "    Uninstalling pytest-8.3.4:\n",
            "      Successfully uninstalled pytest-8.3.4\n",
            "  Attempting uninstall: protobuf\n",
            "    Found existing installation: protobuf 4.25.6\n",
            "    Uninstalling protobuf-4.25.6:\n",
            "      Successfully uninstalled protobuf-4.25.6\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow-metadata 1.16.1 requires protobuf<6.0.0dev,>=4.25.2; python_version >= \"3.11\", but you have protobuf 3.20.3 which is incompatible.\n",
            "grpcio-status 1.62.3 requires protobuf>=4.21.6, but you have protobuf 3.20.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed args-0.1.0 braceexpand-0.1.7 clint-0.5.1 hpsv2-1.2.0 protobuf-3.20.3 pytest-7.2.0 pytest-split-0.8.0 webdataset-0.2.111\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "google"
                ]
              },
              "id": "e65dbd17e1bc424a8de9367ad9eca941"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: diffusers in /usr/local/lib/python3.11/dist-packages (0.32.2)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.11/dist-packages (from diffusers) (8.6.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from diffusers) (3.17.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.23.2 in /usr/local/lib/python3.11/dist-packages (from diffusers) (0.28.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from diffusers) (1.26.4)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from diffusers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from diffusers) (2.32.3)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.11/dist-packages (from diffusers) (0.5.3)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from diffusers) (11.1.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.23.2->diffusers) (2024.10.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.23.2->diffusers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.23.2->diffusers) (6.0.2)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.23.2->diffusers) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.23.2->diffusers) (4.12.2)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.11/dist-packages (from importlib-metadata->diffusers) (3.21.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->diffusers) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->diffusers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->diffusers) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->diffusers) (2025.1.31)\n"
          ]
        }
      ],
      "source": [
        "# HPS dependencies\n",
        "! pip install ftfy regex tqdm\n",
        "! pip install git+https://github.com/openai/CLIP.git\n",
        "! pip install hpsv2\n",
        "\n",
        "# Stable Diffusion dependencies\n",
        "! pip install diffusers"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir -p clip && wget https://github.com/openai/CLIP/raw/main/clip/bpe_simple_vocab_16e6.txt.gz -P /usr/local/lib/python3.11/dist-packages/hpsv2/src/open_clip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NJrLntGwVr1U",
        "outputId": "81af622a-16af-4c66-d1b4-e544ee1ab309"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-03-04 02:24:12--  https://github.com/openai/CLIP/raw/main/clip/bpe_simple_vocab_16e6.txt.gz\n",
            "Resolving github.com (github.com)... 20.27.177.113\n",
            "Connecting to github.com (github.com)|20.27.177.113|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/openai/CLIP/main/clip/bpe_simple_vocab_16e6.txt.gz [following]\n",
            "--2025-03-04 02:24:12--  https://raw.githubusercontent.com/openai/CLIP/main/clip/bpe_simple_vocab_16e6.txt.gz\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1356917 (1.3M) [application/octet-stream]\n",
            "Saving to: ‘/usr/local/lib/python3.11/dist-packages/hpsv2/src/open_clip/bpe_simple_vocab_16e6.txt.gz’\n",
            "\n",
            "bpe_simple_vocab_16 100%[===================>]   1.29M  5.71MB/s    in 0.2s    \n",
            "\n",
            "2025-03-04 02:24:13 (5.71 MB/s) - ‘/usr/local/lib/python3.11/dist-packages/hpsv2/src/open_clip/bpe_simple_vocab_16e6.txt.gz’ saved [1356917/1356917]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Imports"
      ],
      "metadata": {
        "id": "9tTOq5ns8eSs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import re\n",
        "import random\n",
        "from google.colab import drive\n",
        "\n",
        "from abc import ABC, abstractmethod\n",
        "from typing import Union, List, Dict, Optional\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms\n",
        "\n",
        "from diffusers import DiffusionPipeline, StableDiffusionPipeline, StableDiffusion3Pipeline\n",
        "\n",
        "import clip\n",
        "import hpsv2\n",
        "import PIL\n",
        "from PIL import Image"
      ],
      "metadata": {
        "id": "mBkPPyEw8fNB"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. Connect to Google Drive"
      ],
      "metadata": {
        "id": "AEjuf1ym7e3r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "drive.mount(\"/content/drive\",force_remount=True)\n",
        "os.chdir(\"/content/drive/My Drive\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6a3bh3De8hV0",
        "outputId": "33b57401-8df6-4c5d-8107-50e58aff006b"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. Model Code"
      ],
      "metadata": {
        "id": "YReKB8Hv7Uw6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ModelLoadingError(Exception):\n",
        "    \"\"\"Exception raised when there is an error loading the model.\"\"\"\n",
        "    pass\n",
        "\n",
        "class InferenceError(Exception):\n",
        "    \"\"\"Exception raised when an error occurs during inference.\"\"\"\n",
        "    pass\n"
      ],
      "metadata": {
        "id": "j02uLImH0ubF"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class BaseModel(ABC):\n",
        "    @abstractmethod\n",
        "    def load_model(self):\n",
        "        \"\"\"\n",
        "        Load the open-weights model or make an API connection to the closed-source model.\n",
        "        \"\"\"\n",
        "        pass\n",
        "\n",
        "    @abstractmethod\n",
        "    def inference(\n",
        "        self, inputs: Union[List[str], torch.Tensor], captions: Optional[List[str]] = None\n",
        "    ) -> Union[torch.Tensor, List[float]]:\n",
        "        \"\"\"\n",
        "        Run inference on a batch of inputs with optional captions.\n",
        "\n",
        "        Args:\n",
        "            inputs (Union[List[str], torch.Tensor]): A batch of text prompts or a batch of images.\n",
        "            captions (Optional[List[str]]): Optional text captions associated with the inputs for reward models.\n",
        "\n",
        "        Returns:\n",
        "            Union[torch.Tensor, List[float]]: A batch of model outputs or a list of reward scores.\n",
        "        \"\"\"\n",
        "        pass"
      ],
      "metadata": {
        "id": "l1B1q8937Xw1"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class HPSv1Model(BaseModel):\n",
        "    def __init__(self, model_path: str):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            model_path (str): Path to the HPSv1 model checkpoint.\n",
        "        \"\"\"\n",
        "        self.device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "        self.model_path = model_path\n",
        "        self.load_model()\n",
        "\n",
        "    def load_model(self):\n",
        "        try:\n",
        "            self.model, self.preprocess = clip.load(\"ViT-L/14\", device=self.device)\n",
        "            checkpoint = torch.load(self.model_path)\n",
        "\n",
        "            if \"state_dict\" not in checkpoint:\n",
        "                raise ModelLoadingError(\"Checkpoint does not contain 'state_dict'.\")\n",
        "\n",
        "            self.model.load_state_dict(checkpoint[\"state_dict\"])\n",
        "\n",
        "        except FileNotFoundError as e:\n",
        "            raise ModelLoadingError(f\"Model checkpoint not found at '{self.model_path}'.\") from e\n",
        "        except Exception as e:\n",
        "            raise ModelLoadingError(f\"Error loading model: {e}\") from e\n",
        "\n",
        "    def inference(self, inputs: torch.Tensor, captions: List[str]) -> List[float]:\n",
        "        \"\"\"\n",
        "        Runs inference on a batch of images and corresponding captions.\n",
        "        Returns a batch of reward scores.\n",
        "        \"\"\"\n",
        "        if not isinstance(inputs, torch.Tensor):\n",
        "            raise TypeError(\"Expected 'inputs' to be of type torch.Tensor (i.e. images).\")\n",
        "        if not isinstance(captions, list) or not all(isinstance(c, str) for c in captions):\n",
        "            raise TypeError(\"Expected 'captions' to be a list of strings.\")\n",
        "        if inputs.shape[0] != len(captions):\n",
        "            raise ValueError(\"Number of 'inputs' and 'captions' must match.\")\n",
        "\n",
        "        try:\n",
        "            with torch.no_grad():\n",
        "                image_features = self.model.encode_image(inputs.to(self.device))\n",
        "                text_tokens = clip.tokenize(captions).to(self.device)\n",
        "                text_features = self.model.encode_text(text_tokens)\n",
        "\n",
        "                image_features = image_features / image_features.norm(dim=-1, keepdim=True)\n",
        "                text_features = text_features / text_features.norm(dim=-1, keepdim=True)\n",
        "\n",
        "                # Convert cosine similarity scores to percentages as in the original paper\n",
        "                similarity_scores = (image_features @ text_features.T).diag() * 100\n",
        "\n",
        "            return similarity_scores.tolist()\n",
        "        except Exception as e:\n",
        "            raise InferenceError(f\"Inference failed: {e}\") from e"
      ],
      "metadata": {
        "id": "rUVTXwxc7Ybm"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class HPSv2Model(BaseModel):\n",
        "    def __init__(self, model_path: str):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            model_path (str): Path to the HPSv2 model checkpoint. Must be\n",
        "            either 'v2.0' or 'v2.1'.\n",
        "        \"\"\"\n",
        "        if model_path not in [\"v2.0\", \"v2.1\"]:\n",
        "            raise ValueError(\"Expected 'model_path' to be either 'v2.0' or 'v2.1'.\")\n",
        "        self.model_path = model_path\n",
        "        self.load_model()\n",
        "\n",
        "    def load_model(self):\n",
        "        try:\n",
        "            temp_image = PIL.Image.new(\"RGB\", (256, 256), color=(255, 255, 255))\n",
        "            _ = hpsv2.score(temp_image, '<prompt>', hps_version=\"v2.0\") # Also caches the model\n",
        "\n",
        "        except FileNotFoundError as e:\n",
        "            raise ModelLoadingError(f\"Model checkpoint not found at '{self.model_path}'.\") from e\n",
        "        except Exception as e:\n",
        "            raise ModelLoadingError(f\"Error loading model: {e}\") from e\n",
        "\n",
        "    def inference(self, inputs: List[PIL.Image], captions: List[str]) -> List[float]:\n",
        "        \"\"\"\n",
        "        Runs inference on a batch of images and corresponding captions.\n",
        "        Returns a batch of reward scores.\n",
        "        \"\"\"\n",
        "        if not isinstance(inputs, list) or not all(isinstance(i, PIL.Image.Image) for i in inputs):\n",
        "            raise TypeError(\"Expected 'inputs' to be a list of PIL.Image objects.\")\n",
        "        if not isinstance(captions, list) or not all(isinstance(c, str) for c in captions):\n",
        "            raise TypeError(\"Expected 'captions' to be a list of strings.\")\n",
        "        if len(inputs) != len(captions):\n",
        "            raise ValueError(\"Number of 'inputs' and 'captions' must match.\")\n",
        "\n",
        "        try:\n",
        "            similarity_scores = []\n",
        "            for i in range(len(inputs)):\n",
        "                reward = hpsv2.score(inputs[i], captions[i], hps_version=self.model_path)\n",
        "                similarity_scores.append(reward[0] * 100)\n",
        "            return similarity_scores\n",
        "\n",
        "        except Exception as e:\n",
        "            raise InferenceError(f\"Inference failed: {e}\") from e"
      ],
      "metadata": {
        "id": "33IxgoCcTkQ5"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class BaseDiffusionModel(BaseModel):\n",
        "    def __init__(self, model_path: str, offload_to_cpu: bool = False, resolution: int = None, **kwargs):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            model_path (str): Path or repository ID of the diffusion model checkpoint.\n",
        "        \"\"\"\n",
        "        self.seed = 42\n",
        "\n",
        "        self.device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "        self.model_path = model_path\n",
        "        self.offload_to_cpu = offload_to_cpu\n",
        "        self.resolution = resolution\n",
        "        self.kwargs = kwargs\n",
        "\n",
        "        self.diffusion_pipeline = self._get_diffusion_pipeline()\n",
        "        self.load_model()\n",
        "\n",
        "    def _get_diffusion_pipeline(self):\n",
        "        \"\"\" Subclasses should override this to return the correct pipeline. \"\"\"\n",
        "        return DiffusionPipeline\n",
        "\n",
        "    def load_model(self):\n",
        "        try:\n",
        "            self.model = self.diffusion_pipeline.from_pretrained(\n",
        "                self.model_path,\n",
        "                **self.kwargs\n",
        "            ).to(self.device)\n",
        "            if self.offload_to_cpu:\n",
        "                self.model.enable_model_cpu_offload()\n",
        "\n",
        "        except MemoryError as e:\n",
        "            if hasattr(self, \"model\"):\n",
        "                del self.model\n",
        "                torch.cuda.empty_cache()\n",
        "            raise ModelLoadingError(f\"Memory error occurred while loading the model. Consider using a smaller model: {e}\")\n",
        "        except FileNotFoundError as e:\n",
        "            raise ModelLoadingError(f\"Model checkpoint not found at '{self.model_path}'.\") from e\n",
        "        except Exception as e:\n",
        "            raise ModelLoadingError(f\"Failed to load diffusion model: {e}\") from e\n",
        "\n",
        "    def inference(\n",
        "        self, inputs: List[str], captions: Optional[List[str]] = None\n",
        "    ):\n",
        "        \"\"\"\n",
        "        Runs inference on a batch of prompts.\n",
        "        Returns a batch of images corresponding to the prompts.\n",
        "        \"\"\"\n",
        "        if not isinstance(inputs, list) or not all(isinstance(c, str) for c in inputs):\n",
        "            raise TypeError(\"Expected 'inputs' to be a list of strings.\")\n",
        "\n",
        "        try:\n",
        "            # Create one generator per prompt to ensure reproducibility\n",
        "            generators = [\n",
        "                torch.Generator(self.device).manual_seed(self.seed) for _ in range(len(inputs))\n",
        "            ]\n",
        "            if self.resolution:\n",
        "                images = self.model(\n",
        "                    prompt=inputs, generator=generators,\n",
        "                    height=self.resolution, width=self.resolution # use 1:1 aspect ratio\n",
        "                ).images\n",
        "                return images\n",
        "            else:\n",
        "                images = self.model(\n",
        "                    prompt=inputs, generator=generators,\n",
        "                ).images\n",
        "                return images\n",
        "\n",
        "        except Exception as e:\n",
        "            raise InferenceError(f\"Inference failed: {e}\")"
      ],
      "metadata": {
        "id": "kVVBTkx4JaQf"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class StableDiffusionModel(BaseDiffusionModel):\n",
        "    def __init__(self, model_path: str, offload_to_cpu: bool = False, resolution: int = None, **kwargs):\n",
        "        \"\"\"\n",
        "        Note:\n",
        "            model_path (str): Path to the Stable Diffusion model.\n",
        "                              Must include 'stable-diffusion-1', 'stable-diffusion-2', or 'stable-diffusion-3' after '<repo-owner>/'\n",
        "                              for simplicity.\n",
        "        \"\"\"\n",
        "\n",
        "        # Load the model with float16 precision.\n",
        "        # If your GPU supports torch.bfloat16 for lower memory usage with similar precision to FP32,\n",
        "        # consider switching the torch_dtype accordingly.\n",
        "        if \"torch_dtype\" not in kwargs:\n",
        "            kwargs[\"torch_dtype\"] = torch.float16\n",
        "        super().__init__(model_path, offload_to_cpu, resolution, **kwargs)\n",
        "\n",
        "    def _get_diffusion_pipeline(self):\n",
        "        version_tag = self.model_path.split(\"/\")[-1].lower()\n",
        "        if re.search(r'(stable-diffusion-1|v-?1)', version_tag):\n",
        "            return StableDiffusionPipeline\n",
        "        elif re.search(r'(stable-diffusion-2|v-?2)', version_tag):\n",
        "            return DiffusionPipeline\n",
        "        elif re.search(r'(stable-diffusion-3|v-?3)', version_tag):\n",
        "            return StableDiffusion3Pipeline\n",
        "        else:\n",
        "            raise ModelLoadingError(\n",
        "                \"Model path must contain one of: 'stable-diffusion-1', 'stable-diffusion-2', or 'stable-diffusion-3'.\"\n",
        "            )"
      ],
      "metadata": {
        "id": "QII1xUW_Dv7d"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "5. Test HPSv2 Benchmark"
      ],
      "metadata": {
        "id": "hwQRDI8d9s-r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class DatasetFormatError(Exception):\n",
        "    \"\"\"Raised when the dataset format is incorrect.\"\"\"\n",
        "    pass\n",
        "\n",
        "class DatasetLoadingError(Exception):\n",
        "    \"\"\"Raised when the dataset fails to load properly.\"\"\"\n",
        "    pass"
      ],
      "metadata": {
        "id": "8rQNX2HT_sef"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class BasePromptDataset(Dataset, ABC):\n",
        "    def __init__(self):\n",
        "        try:\n",
        "            self.data = self.load_dataset()\n",
        "        except Exception as e:\n",
        "            raise DatasetLoadingError(f\"Failed to load dataset: {e}\")\n",
        "\n",
        "        if not isinstance(self.data, dict):\n",
        "            raise DatasetFormatError(f\"Expected 'load_dataset()' to return a dictionary, got '{type(self.data)}'.\")\n",
        "\n",
        "        for key, prompts in self.data.items():\n",
        "            if not isinstance(prompts, list) or not all(isinstance(p, str) for p in prompts):\n",
        "                raise DatasetFormatError(f\"Expected a list of strings for category '{key}', but got '{type(prompts)}'\")\n",
        "\n",
        "        # Precompute samples with round-robin ordering\n",
        "        self.samples = self._create_round_robin_samples()\n",
        "\n",
        "    @abstractmethod\n",
        "    def load_dataset(self) -> Dict[str, List[str]]:\n",
        "        \"\"\"To be implemented by subclasses.\"\"\"\n",
        "        pass\n",
        "\n",
        "    def _create_round_robin_samples(self) -> List[Dict[str, str]]:\n",
        "        \"\"\"Ensure fair round-robin interleaving of prompts from all categories.\"\"\"\n",
        "        samples = []\n",
        "        categories = list(self.data.keys())\n",
        "        category_prompts = [self.data[cat] for cat in categories]\n",
        "\n",
        "        if not categories or all(len(prompts) == 0 for prompts in category_prompts):\n",
        "            raise DatasetFormatError(\"Dataset is empty or contains only empty categories.\")\n",
        "\n",
        "        max_length = max(len(prompts) for prompts in category_prompts)\n",
        "\n",
        "        # Round-robin interleaving\n",
        "        for i in range(max_length):\n",
        "            for cat_idx, category in enumerate(categories):\n",
        "                prompts = category_prompts[cat_idx]\n",
        "                if len(prompts) > 0:\n",
        "                    prompt = prompts[i % len(prompts)]  # Cycle back for shorter lists\n",
        "                    samples.append({\"category\": category, \"prompt\": prompt})\n",
        "\n",
        "        return samples\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.samples)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.samples[idx]\n"
      ],
      "metadata": {
        "id": "tEhkl8Sv9wE2"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class RoundRobinSampler(torch.utils.data.Sampler):\n",
        "    def __init__(self, dataset: BasePromptDataset):\n",
        "        self.dataset = dataset\n",
        "        self.indices = self._generate_indices()\n",
        "\n",
        "    def _generate_indices(self):\n",
        "        \"\"\"\n",
        "        Assume dataset.data has equal length lists per category.\n",
        "\n",
        "        For each category, create a shuffled list of indices corresponding to that category's samples.\n",
        "        Since BasePromptDataset precomputes samples in round-robin order, we need to map from category + position\n",
        "        to the flat sample index.\n",
        "\n",
        "        In our round-robin samples, the ordering is:\n",
        "        index 0: category1, index 1: category2, ..., index N: category1\n",
        "\n",
        "        Let K = number of categories,\n",
        "        Then the sample index for category j at position i is: i*K + j.\n",
        "        \"\"\"\n",
        "        categories = list(self.dataset.data.keys())\n",
        "        num_per_category = len(next(iter(self.dataset.data.values())))\n",
        "        K = len(categories)\n",
        "\n",
        "        category_indices = {}\n",
        "        for j, cat in enumerate(categories):\n",
        "            indices = [i * K + j for i in range(num_per_category)]\n",
        "            random.shuffle(indices)\n",
        "            category_indices[cat] = indices\n",
        "\n",
        "        ordered_indices = []\n",
        "        for i in range(num_per_category):\n",
        "            for cat in categories:\n",
        "                ordered_indices.append(category_indices[cat][i])\n",
        "        return ordered_indices\n",
        "\n",
        "    def __iter__(self):\n",
        "        return iter(self.indices)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.indices)\n"
      ],
      "metadata": {
        "id": "Y06S5yClCub4"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class HPSV2PromptDataset(BasePromptDataset):\n",
        "    def load_dataset(self) -> Dict[str, List[str]]:\n",
        "        all_prompts = hpsv2.benchmark_prompts(\"all\")\n",
        "        return dict(all_prompts.items())"
      ],
      "metadata": {
        "id": "tyOtdnPk918R"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = HPSV2PromptDataset()\n",
        "sampler = RoundRobinSampler(dataset)\n",
        "dataloader = DataLoader(dataset, batch_size=5, sampler=sampler)\n",
        "\n",
        "count = 0\n",
        "for batch in dataloader:\n",
        "    print(batch)\n",
        "    count += 1\n",
        "    if count == 10:\n",
        "      break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OEuvMS-297bt",
        "outputId": "b02e27f8-5cc1-4587-8cde-d2d8bbc5cb69"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'category': ['anime', 'concept-art', 'paintings', 'photo', 'anime'], 'prompt': ['Anime oil painting of Rem from Re Zero.', 'The image is titled \"Burning Memory\" and features dark, dramatic, and highly detailed artwork by multiple artists, depicting a scene from the video game Bloodborne.', 'Oil painting of a man under a tree in the rain, by Greg Rutkowski.', 'A desk sitting next to a showroom of cars in it.', 'A digital painting of a cyberpunk anime woman with intricate and highly detailed features.']}\n",
            "{'category': ['concept-art', 'paintings', 'photo', 'anime', 'concept-art'], 'prompt': ['A surreal image featuring a rainbow and neon glow with a biohazard scientist in a laboratory evacuation scene, showcasing a mix of gothic and neo-gothic styles with rich colors.', 'A creepy man dressed as a chicken is frightening children in a painting by Bussiere, Mullins, and Leyendecker.', 'A group of waiters standing in a line. ', 'A young man in a small Tokyo room with an open window sits at his computer surrounded by anime posters and appliances, while a small bed remains unmade in the background.', 'An entrance to a dungeon at the base of an ancient mountain in the morning light with a Studio Ghibli inspired style, possibly done by Hayao Miyazaki.']}\n",
            "{'category': ['paintings', 'photo', 'anime', 'concept-art', 'paintings'], 'prompt': ['An oil painting of a treasure lost in a rainforest.', 'there is a man sticking his head out of a train window', 'Bob Ross riding a brown bear in Alaska.', 'A giant guardian wearing road sign armor, a popular character design on Artstation.', 'The image portrays Ophelia with a detailed and elegant face, featuring wonderful eyes, wearing an intricate dress, and created with hyperrealistic painting techniques.']}\n",
            "{'category': ['photo', 'anime', 'concept-art', 'paintings', 'photo'], 'prompt': ['a bus with a view of a lot of traffic and the back of another bus with a billboard on the back end', \"Tom and Jerry are featured in Iron Maiden's album Live After Death in place of their usual mascot, Eddie.\", 'The image is a horror movie poster featuring the kuntilanak antapani, created by Hanung Bramantyo, Joko Anwar, and Stephen Spielberg using Unreal Engine, Blender, and Photoshop software.', 'A pen illustration of a man wrestling his phone by Gustave Doré with crosshatching and pops of colorful Ben Day dots.', 'young man looking a different image of himself in the mirror']}\n",
            "{'category': ['anime', 'concept-art', 'paintings', 'photo', 'anime'], 'prompt': ['A frog wearing an anime-inspired onesie.', 'A transparent demon in clothing chasing someone around a dinner table in a dark and terrifying setting.', 'A portrait of Boromir with a sword.', 'there is a chef making food as people watch', 'A cute humanoid cat soldier wears a yellow raincoat, carries a rifle, and ventures through a dense forest, looking back over their shoulder.']}\n",
            "{'category': ['concept-art', 'paintings', 'photo', 'anime', 'concept-art'], 'prompt': ['Portrait of Leonardo da Vinci as a steampunk cyborg.', 'A baroque pattern that seamlessly tiles.', 'A man walking around with his dog and sheep.', 'A cat with wings featured in a comic book story.', 'The image depicts Ciri from League of Legends, with fluorescent skin, and features a hyper-detailed, smooth render created using a cinematic lighting and rendered in Unreal Engine 5 and Octane.']}\n",
            "{'category': ['paintings', 'photo', 'anime', 'concept-art', 'paintings'], 'prompt': ['A digital painting of a ninja gaiden girl in an armored dieselpunk wardrobe at snowy fuji mountain moonlight.', 'A bike sitting next to a brick wall in the open.', 'An art piece depicting a Capybara wearing sunglasses.', 'Winter-themed vector art panel for CNC cutting machines with a unique winter design.', 'A gouache painting by Claude Monet of ships docked at the harbor.']}\n",
            "{'category': ['photo', 'anime', 'concept-art', 'paintings', 'photo'], 'prompt': ['a bunch of people in a kitchen getting food ready', 'A portrait of a cheerful, young Latino magician holding a grand and pink coffee mug, surrounded by stars and magic.', 'Black and gold egg-shaped mech suit in a winter village during a blizzard, with volumetric lighting and lightning in the background at night time.', 'Portrait of Herzl as a florist, painted by Van Gogh.', 'A dog sits in front of and watches the television.']}\n",
            "{'category': ['anime', 'concept-art', 'paintings', 'photo', 'anime'], 'prompt': ['SpongeBob in Dragon Ball style.', 'Detailed image of a creepy family in deep space, created by Richard Corben and Katsuhiro Otomo, with intricate and extremely detailed artwork.', 'A cinematic fashion portrait of a Hindu goddess standing in a beautiful garden.', 'a bike resting in the sand with a blender built on top', 'An illustrated cat with a black spot on her trunk sits in an old house with a window overlooking a blue sky.']}\n",
            "{'category': ['concept-art', 'paintings', 'photo', 'anime', 'concept-art'], 'prompt': ['Adventurers walking along a wall beneath cliffs in a fantasy setting.', 'An image portraying Barry Lyndon.', 'Some men and women in white shirts and bow ties standing in a row.', 'A girl reading on a bench in an abandoned train station depicted in stylized anime art.', 'A league of legends concept art of a young female scientist holding a small black hole in a laboratory.']}\n"
          ]
        }
      ]
    }
  ]
}