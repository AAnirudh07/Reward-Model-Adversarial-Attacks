# Reward-Model-Adversarial-Attacks


### References
1. Wu, X., Sun, K., Zhu, F., Zhao, R., & Li, H. (2023). Human Preference Score: Better Aligning Text-to-Image Models with Human Preference. ArXiv. https://arxiv.org/abs/2303.14420