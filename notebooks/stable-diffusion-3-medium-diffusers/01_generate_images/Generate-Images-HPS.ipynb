{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "9f98bc2e2217477aa7003918e8f9b319": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_fbb1d6be963a4993b7fa8c970b221140",
              "IPY_MODEL_d7692de48712479aa9ea3e8dd714f2be",
              "IPY_MODEL_5b7c1a3566644490b1fe0c5d4b01f032"
            ],
            "layout": "IPY_MODEL_48130d221cf0441fbc477ba7c4db149a"
          }
        },
        "fbb1d6be963a4993b7fa8c970b221140": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8f54b32085f34cf9820ea408b1e32445",
            "placeholder": "​",
            "style": "IPY_MODEL_2363dc132d3f4eb487b904d6d1d27bbe",
            "value": "Loading pipeline components...: 100%"
          }
        },
        "d7692de48712479aa9ea3e8dd714f2be": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a0faed6f5577489685e5a6b9ad1d395e",
            "max": 7,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9f180b546e1c4920b8175f59f857337e",
            "value": 7
          }
        },
        "5b7c1a3566644490b1fe0c5d4b01f032": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_aa8a521493264f8d98a1d07579e5a493",
            "placeholder": "​",
            "style": "IPY_MODEL_fc983de7840a48a08cd0549b6344b786",
            "value": " 7/7 [00:05&lt;00:00,  1.13s/it]"
          }
        },
        "48130d221cf0441fbc477ba7c4db149a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8f54b32085f34cf9820ea408b1e32445": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2363dc132d3f4eb487b904d6d1d27bbe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a0faed6f5577489685e5a6b9ad1d395e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9f180b546e1c4920b8175f59f857337e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "aa8a521493264f8d98a1d07579e5a493": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fc983de7840a48a08cd0549b6344b786": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "32759be5c6e7480799d2e1b85272e8b6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_aa772f701c8b42bdbcd54330b7c35b8e",
              "IPY_MODEL_ef739a9b955c48a9854dc9c296d362a0",
              "IPY_MODEL_fdc3081def0a436d95bb79226156215f"
            ],
            "layout": "IPY_MODEL_7809096174b04a84aefc806052297411"
          }
        },
        "aa772f701c8b42bdbcd54330b7c35b8e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bae6d27ebeac4330a89d0746405dabe8",
            "placeholder": "​",
            "style": "IPY_MODEL_cc46b5e284ed4f61b5eab7b72d6ab4f8",
            "value": "100%"
          }
        },
        "ef739a9b955c48a9854dc9c296d362a0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_75a57aa855b74e479737fd13f0b2d5ef",
            "max": 28,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9052651e2b9944478a45f7349a3d74e3",
            "value": 28
          }
        },
        "fdc3081def0a436d95bb79226156215f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3f86fc1ebdac48ceac2ff1f97c3b55f6",
            "placeholder": "​",
            "style": "IPY_MODEL_606f88d809544428987a5d2a51102abc",
            "value": " 28/28 [02:15&lt;00:00,  4.90s/it]"
          }
        },
        "7809096174b04a84aefc806052297411": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bae6d27ebeac4330a89d0746405dabe8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cc46b5e284ed4f61b5eab7b72d6ab4f8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "75a57aa855b74e479737fd13f0b2d5ef": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9052651e2b9944478a45f7349a3d74e3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3f86fc1ebdac48ceac2ff1f97c3b55f6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "606f88d809544428987a5d2a51102abc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3b40bb4f107f4d328f820ce58ec67ecb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_97a855e118f94779bd7d83bac0a7a2e4",
              "IPY_MODEL_c2070caa349f4ffb9bc309c5a4def34b",
              "IPY_MODEL_ce1454b1515345a4970ba4e4fef85d9d"
            ],
            "layout": "IPY_MODEL_1ba2fbf9610f4817af714693ec0435c1"
          }
        },
        "97a855e118f94779bd7d83bac0a7a2e4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6008de7448c74ad98ce6478fa0c20244",
            "placeholder": "​",
            "style": "IPY_MODEL_51e9d43ecd9f406e8da592cf3913d2aa",
            "value": "100%"
          }
        },
        "c2070caa349f4ffb9bc309c5a4def34b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a312fe828e194bf981369798a8d83f1a",
            "max": 28,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_21467b05c1114967be68d30f86dc5c9b",
            "value": 28
          }
        },
        "ce1454b1515345a4970ba4e4fef85d9d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b158e721242c4b2f921ae16c97169f89",
            "placeholder": "​",
            "style": "IPY_MODEL_68278a34dd034a73a47b5aacaffe343f",
            "value": " 28/28 [02:15&lt;00:00,  4.92s/it]"
          }
        },
        "1ba2fbf9610f4817af714693ec0435c1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6008de7448c74ad98ce6478fa0c20244": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "51e9d43ecd9f406e8da592cf3913d2aa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a312fe828e194bf981369798a8d83f1a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "21467b05c1114967be68d30f86dc5c9b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b158e721242c4b2f921ae16c97169f89": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "68278a34dd034a73a47b5aacaffe343f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "1. Install Dependencies"
      ],
      "metadata": {
        "id": "pep10KJ56zU4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7WLA6_b66tWX",
        "outputId": "f8ee4d8a-b74a-4031-a4b4-df4bcba9a579"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: ftfy in /usr/local/lib/python3.11/dist-packages (6.3.1)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.11/dist-packages (2024.11.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (4.67.1)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.11/dist-packages (from ftfy) (0.2.13)\n",
            "Collecting git+https://github.com/openai/CLIP.git\n",
            "  Cloning https://github.com/openai/CLIP.git to /tmp/pip-req-build-is9d8e99\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/openai/CLIP.git /tmp/pip-req-build-is9d8e99\n",
            "  Resolved https://github.com/openai/CLIP.git to commit dcba3cb2e2827b402d2701e7e1c7d9fed8a20ef1\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: ftfy in /usr/local/lib/python3.11/dist-packages (from clip==1.0) (6.3.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from clip==1.0) (24.2)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.11/dist-packages (from clip==1.0) (2024.11.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from clip==1.0) (4.67.1)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (from clip==1.0) (2.5.1+cu124)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (from clip==1.0) (0.20.1+cu124)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.11/dist-packages (from ftfy->clip==1.0) (0.2.13)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch->clip==1.0) (3.17.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch->clip==1.0) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch->clip==1.0) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch->clip==1.0) (3.1.5)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch->clip==1.0) (2024.10.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->clip==1.0) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->clip==1.0) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->clip==1.0) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch->clip==1.0) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch->clip==1.0) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch->clip==1.0) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch->clip==1.0) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch->clip==1.0) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch->clip==1.0) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch->clip==1.0) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->clip==1.0) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->clip==1.0) (12.4.127)\n",
            "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch->clip==1.0) (3.1.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch->clip==1.0) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch->clip==1.0) (1.3.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchvision->clip==1.0) (1.26.4)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision->clip==1.0) (11.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch->clip==1.0) (3.0.2)\n",
            "Requirement already satisfied: hpsv2 in /usr/local/lib/python3.11/dist-packages (1.2.0)\n",
            "Requirement already satisfied: torch>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from hpsv2) (2.5.1+cu124)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (from hpsv2) (0.20.1+cu124)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.11/dist-packages (from hpsv2) (2024.11.6)\n",
            "Requirement already satisfied: ftfy in /usr/local/lib/python3.11/dist-packages (from hpsv2) (6.3.1)\n",
            "Requirement already satisfied: einops in /usr/local/lib/python3.11/dist-packages (from hpsv2) (0.8.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from hpsv2) (2.2.2)\n",
            "Requirement already satisfied: braceexpand in /usr/local/lib/python3.11/dist-packages (from hpsv2) (0.1.7)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from hpsv2) (2024.10.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from hpsv2) (4.67.1)\n",
            "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.11/dist-packages (from hpsv2) (0.28.1)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.11/dist-packages (from hpsv2) (0.2.0)\n",
            "Requirement already satisfied: protobuf<4 in /usr/local/lib/python3.11/dist-packages (from hpsv2) (3.20.3)\n",
            "Requirement already satisfied: timm in /usr/local/lib/python3.11/dist-packages (from hpsv2) (1.0.15)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (from hpsv2) (4.48.3)\n",
            "Requirement already satisfied: webdataset in /usr/local/lib/python3.11/dist-packages (from hpsv2) (0.2.111)\n",
            "Requirement already satisfied: pyarrow in /usr/local/lib/python3.11/dist-packages (from hpsv2) (18.1.0)\n",
            "Requirement already satisfied: pytest-split==0.8.0 in /usr/local/lib/python3.11/dist-packages (from hpsv2) (0.8.0)\n",
            "Requirement already satisfied: pytest==7.2.0 in /usr/local/lib/python3.11/dist-packages (from hpsv2) (7.2.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from hpsv2) (2.32.3)\n",
            "Requirement already satisfied: clint in /usr/local/lib/python3.11/dist-packages (from hpsv2) (0.5.1)\n",
            "Requirement already satisfied: attrs>=19.2.0 in /usr/local/lib/python3.11/dist-packages (from pytest==7.2.0->hpsv2) (25.1.0)\n",
            "Requirement already satisfied: iniconfig in /usr/local/lib/python3.11/dist-packages (from pytest==7.2.0->hpsv2) (2.0.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from pytest==7.2.0->hpsv2) (24.2)\n",
            "Requirement already satisfied: pluggy<2.0,>=0.12 in /usr/local/lib/python3.11/dist-packages (from pytest==7.2.0->hpsv2) (1.5.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=1.9.0->hpsv2) (3.17.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9.0->hpsv2) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.9.0->hpsv2) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9.0->hpsv2) (3.1.5)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9.0->hpsv2) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9.0->hpsv2) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9.0->hpsv2) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9.0->hpsv2) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9.0->hpsv2) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9.0->hpsv2) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9.0->hpsv2) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9.0->hpsv2) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9.0->hpsv2) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9.0->hpsv2) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9.0->hpsv2) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9.0->hpsv2) (12.4.127)\n",
            "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9.0->hpsv2) (3.1.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9.0->hpsv2) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.9.0->hpsv2) (1.3.0)\n",
            "Requirement already satisfied: args in /usr/local/lib/python3.11/dist-packages (from clint->hpsv2) (0.1.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.11/dist-packages (from ftfy->hpsv2) (0.2.13)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub->hpsv2) (6.0.2)\n",
            "Requirement already satisfied: numpy>=1.23.2 in /usr/local/lib/python3.11/dist-packages (from pandas->hpsv2) (1.26.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->hpsv2) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->hpsv2) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->hpsv2) (2025.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->hpsv2) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->hpsv2) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->hpsv2) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->hpsv2) (2025.1.31)\n",
            "Requirement already satisfied: safetensors in /usr/local/lib/python3.11/dist-packages (from timm->hpsv2) (0.5.3)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision->hpsv2) (11.1.0)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers->hpsv2) (0.21.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->hpsv2) (1.17.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.9.0->hpsv2) (3.0.2)\n",
            "Requirement already satisfied: diffusers in /usr/local/lib/python3.11/dist-packages (0.32.2)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.11/dist-packages (from diffusers) (8.6.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from diffusers) (3.17.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.23.2 in /usr/local/lib/python3.11/dist-packages (from diffusers) (0.28.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from diffusers) (1.26.4)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from diffusers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from diffusers) (2.32.3)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.11/dist-packages (from diffusers) (0.5.3)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from diffusers) (11.1.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.23.2->diffusers) (2024.10.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.23.2->diffusers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.23.2->diffusers) (6.0.2)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.23.2->diffusers) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.23.2->diffusers) (4.12.2)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.11/dist-packages (from importlib-metadata->diffusers) (3.21.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->diffusers) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->diffusers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->diffusers) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->diffusers) (2025.1.31)\n"
          ]
        }
      ],
      "source": [
        "# HPS dependencies\n",
        "! pip install ftfy regex tqdm\n",
        "! pip install git+https://github.com/openai/CLIP.git\n",
        "! pip install hpsv2\n",
        "\n",
        "# Stable Diffusion dependencies\n",
        "! pip install diffusers"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir -p clip && wget https://github.com/openai/CLIP/raw/main/clip/bpe_simple_vocab_16e6.txt.gz -P /usr/local/lib/python3.11/dist-packages/hpsv2/src/open_clip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NJrLntGwVr1U",
        "outputId": "57639a94-413d-43fc-80b5-0dcdee39b767"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-03-08 05:19:28--  https://github.com/openai/CLIP/raw/main/clip/bpe_simple_vocab_16e6.txt.gz\n",
            "Resolving github.com (github.com)... 20.205.243.166\n",
            "Connecting to github.com (github.com)|20.205.243.166|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/openai/CLIP/main/clip/bpe_simple_vocab_16e6.txt.gz [following]\n",
            "--2025-03-08 05:19:28--  https://raw.githubusercontent.com/openai/CLIP/main/clip/bpe_simple_vocab_16e6.txt.gz\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1356917 (1.3M) [application/octet-stream]\n",
            "Saving to: ‘/usr/local/lib/python3.11/dist-packages/hpsv2/src/open_clip/bpe_simple_vocab_16e6.txt.gz.4’\n",
            "\n",
            "bpe_simple_vocab_16 100%[===================>]   1.29M  --.-KB/s    in 0.008s  \n",
            "\n",
            "2025-03-08 05:19:29 (158 MB/s) - ‘/usr/local/lib/python3.11/dist-packages/hpsv2/src/open_clip/bpe_simple_vocab_16e6.txt.gz.4’ saved [1356917/1356917]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Imports"
      ],
      "metadata": {
        "id": "9tTOq5ns8eSs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import re\n",
        "import gc\n",
        "from datetime import datetime\n",
        "import random\n",
        "import argparse\n",
        "from tqdm import tqdm\n",
        "from google.colab import drive\n",
        "\n",
        "from abc import ABC, abstractmethod\n",
        "from typing import Union, List, Dict, Tuple, Optional\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms\n",
        "\n",
        "from diffusers import DiffusionPipeline, StableDiffusionPipeline, StableDiffusion3Pipeline\n",
        "\n",
        "import clip\n",
        "import hpsv2\n",
        "from hpsv2.src.open_clip import create_model_and_transforms, get_tokenizer\n",
        "import PIL\n",
        "from PIL import Image"
      ],
      "metadata": {
        "id": "mBkPPyEw8fNB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "98a94c1d-5c4c-4310-de35-0d5834a810d0"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers\n",
            "  warnings.warn(f\"Importing from {__name__} is deprecated, please import via timm.layers\", FutureWarning)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. Connect to Google Drive"
      ],
      "metadata": {
        "id": "AEjuf1ym7e3r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "drive.mount(\"/content/drive\",force_remount=True)\n",
        "os.chdir(\"/content/drive/My Drive\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6a3bh3De8hV0",
        "outputId": "c8e168c9-6318-4801-c4c0-9f0d91512605"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. Model Code"
      ],
      "metadata": {
        "id": "YReKB8Hv7Uw6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ModelLoadingError(Exception):\n",
        "    \"\"\"Exception raised when there is an error loading the model.\"\"\"\n",
        "    pass\n",
        "\n",
        "class InferenceError(Exception):\n",
        "    \"\"\"Exception raised when an error occurs during inference.\"\"\"\n",
        "    pass"
      ],
      "metadata": {
        "id": "j02uLImH0ubF"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class BaseModel(ABC):\n",
        "    @abstractmethod\n",
        "    def load_model(self):\n",
        "        \"\"\"\n",
        "        Load the open-weights model or make an API connection to the closed-source model.\n",
        "        \"\"\"\n",
        "        pass\n",
        "\n",
        "    @abstractmethod\n",
        "    def inference(\n",
        "        self, inputs: Union[List[str], torch.Tensor], captions: Optional[List[str]] = None\n",
        "    ) -> Union[torch.Tensor, List[float]]:\n",
        "        \"\"\"\n",
        "        Run inference on a batch of inputs with optional captions.\n",
        "\n",
        "        Args:\n",
        "            inputs (Union[List[str], torch.Tensor]): A batch of text prompts or a batch of images.\n",
        "            captions (Optional[List[str]]): Optional text captions associated with the inputs for reward models.\n",
        "\n",
        "        Returns:\n",
        "            Union[torch.Tensor, List[float]]: A batch of model outputs or a list of reward scores.\n",
        "        \"\"\"\n",
        "        pass"
      ],
      "metadata": {
        "id": "l1B1q8937Xw1"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class HPSv1Model(BaseModel):\n",
        "    def __init__(self, model_path: str):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            model_path (str): Path to the HPSv1 model checkpoint.\n",
        "        \"\"\"\n",
        "        self.device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "        self.model_path = model_path\n",
        "        self.load_model()\n",
        "\n",
        "    def load_model(self):\n",
        "        try:\n",
        "            self.model, self.preprocess_function = clip.load(\"ViT-L/14\", device=self.device)\n",
        "            checkpoint = torch.load(self.model_path)\n",
        "\n",
        "            if \"state_dict\" not in checkpoint:\n",
        "                raise ModelLoadingError(\"Checkpoint does not contain 'state_dict'.\")\n",
        "\n",
        "            self.model.load_state_dict(checkpoint[\"state_dict\"])\n",
        "            self.tokenizer = clip.tokenize\n",
        "            self.model.eval()\n",
        "\n",
        "        except FileNotFoundError as e:\n",
        "            raise ModelLoadingError(f\"Model checkpoint not found at '{self.model_path}'.\") from e\n",
        "        except Exception as e:\n",
        "            raise ModelLoadingError(f\"Error loading model: {e}\") from e\n",
        "\n",
        "    def inference(self, inputs: torch.Tensor, captions: Union[List[str], torch.Tensor]) -> List[float]:\n",
        "        \"\"\"\n",
        "        Runs inference on a batch of images and corresponding captions.\n",
        "        Returns a batch of reward scores.\n",
        "        \"\"\"\n",
        "        if not isinstance(inputs, torch.Tensor):\n",
        "            raise TypeError(\"Expected 'inputs' to be of type torch.Tensor (i.e. images).\")\n",
        "        if not isinstance(captions, list) or not all(isinstance(c, str) for c in captions):\n",
        "            raise TypeError(\"Expected 'captions' to be a list of strings.\")\n",
        "        if inputs.shape[0] != len(captions):\n",
        "            raise ValueError(\"Number of 'inputs' and 'captions' must match.\")\n",
        "\n",
        "        try:\n",
        "            with torch.no_grad():\n",
        "                image_features = self.model.encode_image(inputs.to(self.device))\n",
        "\n",
        "                if not isinstance(captions, torch.Tensor):\n",
        "                    text_tokens = self.tokenizer(captions).to(self.device)\n",
        "                else:\n",
        "                    text_tokens = captions.to(self.device)\n",
        "                text_features = self.model.encode_text(text_tokens)\n",
        "\n",
        "                image_features = image_features / image_features.norm(dim=-1, keepdim=True)\n",
        "                text_features = text_features / text_features.norm(dim=-1, keepdim=True)\n",
        "\n",
        "                # Convert cosine similarity scores to percentages as in the original paper\n",
        "                similarity_scores = (image_features @ text_features.T).diag() * 100\n",
        "            return similarity_scores.tolist()\n",
        "        except Exception as e:\n",
        "            raise InferenceError(f\"Inference failed: {e}\") from e\n",
        "\n",
        "    def inference_with_grad(self, inputs: torch.Tensor, captions: List[str]) -> List[float]:\n",
        "        \"\"\"\n",
        "        Runs inference on a batch of images and corresponding captions.\n",
        "        Returns a batch of reward scores.\n",
        "        \"\"\"\n",
        "        if not isinstance(inputs, torch.Tensor):\n",
        "            raise TypeError(\"Expected 'inputs' to be of type torch.Tensor (i.e. images).\")\n",
        "        if not isinstance(captions, list) or not all(isinstance(c, str) for c in captions):\n",
        "            raise TypeError(\"Expected 'captions' to be a list of strings.\")\n",
        "        if inputs.shape[0] != len(captions):\n",
        "            raise ValueError(\"Number of 'inputs' and 'captions' must match.\")\n",
        "\n",
        "        try:\n",
        "            text_tokens = clip.tokenize(captions).to(self.device)\n",
        "            image_features, text_features = self.model(inputs, text_tokens)\n",
        "            return (image_features @ text_features.T).diag() * 100\n",
        "        except Exception as e:\n",
        "            raise InferenceError(f\"Inference failed: {e}\") from e"
      ],
      "metadata": {
        "id": "rUVTXwxc7Ybm"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class HPSv2Model(BaseModel):\n",
        "    def __init__(self, model_path: str):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            model_path (str): Path to the HPSv2 model checkpoint.\n",
        "        \"\"\"\n",
        "        self.device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "        self.model_path = model_path\n",
        "        self.load_model()\n",
        "\n",
        "    def load_model(self):\n",
        "        try:\n",
        "            self.model, _, self.preprocess_function = create_model_and_transforms(\n",
        "                \"ViT-H-14\",\n",
        "                \"laion2B-s32B-b79K\",\n",
        "                precision=\"amp\",\n",
        "                device=self.device,\n",
        "                jit=False,\n",
        "                force_quick_gelu=False,\n",
        "                force_custom_text=False,\n",
        "                force_patch_dropout=False,\n",
        "                force_image_size=None,\n",
        "                pretrained_image=False,\n",
        "                image_mean=None,\n",
        "                image_std=None,\n",
        "                light_augmentation=True,\n",
        "                aug_cfg={},\n",
        "                output_dict=True,\n",
        "                with_score_predictor=False,\n",
        "                with_region_predictor=False\n",
        "            )\n",
        "\n",
        "            checkpoint = torch.load(self.model_path)\n",
        "            if \"state_dict\" not in checkpoint:\n",
        "                raise ModelLoadingError(\"Checkpoint does not contain 'state_dict'.\")\n",
        "\n",
        "            self.model.load_state_dict(checkpoint[\"state_dict\"])\n",
        "            self.tokenizer = get_tokenizer(\"ViT-H-14\")\n",
        "            self.model.eval()\n",
        "\n",
        "        except FileNotFoundError as e:\n",
        "            raise ModelLoadingError(f\"Model checkpoint not found at '{self.model_path}'.\") from e\n",
        "        except Exception as e:\n",
        "            raise ModelLoadingError(f\"Error loading model: {e}\") from e\n",
        "\n",
        "    def inference(self, inputs: torch.Tensor, captions: Union[List[str], torch.Tensor]) -> List[float]:\n",
        "        \"\"\"\n",
        "        Runs inference on a batch of images and corresponding captions.\n",
        "        Returns a batch of reward scores.\n",
        "        \"\"\"\n",
        "        if not isinstance(inputs, list) or not all(isinstance(i, PIL.Image.Image) for i in inputs):\n",
        "            raise TypeError(\"Expected 'inputs' to be a list of PIL.Image objects.\")\n",
        "        if not isinstance(captions, list) or not all(isinstance(c, str) for c in captions):\n",
        "            raise TypeError(\"Expected 'captions' to be a list of strings.\")\n",
        "        if len(inputs) != len(captions):\n",
        "            raise ValueError(\"Number of 'inputs' and 'captions' must match.\")\n",
        "\n",
        "        try:\n",
        "            with torch.no_grad():\n",
        "                if not isinstance(captions, torch.Tensor):\n",
        "                    text_tokens = self.tokenizer(captions).to(self.device)\n",
        "                else:\n",
        "                    text_tokens = captions.to(self.device)\n",
        "\n",
        "                with torch.cuda.amp.autocast():\n",
        "                    outputs = self.model(inputs, text_tokens)\n",
        "                    image_features, text_features = outputs[\"image_features\"], outputs[\"text_features\"]\n",
        "                    similarity_scores = (image_features @ text_features.T).diag() * 100\n",
        "                return similarity_scores.tolist()\n",
        "\n",
        "        except Exception as e:\n",
        "            raise InferenceError(f\"Inference failed: {e}\") from e\n",
        "\n",
        "\n",
        "    def inference_with_grad(self, inputs: torch.Tensor, captions: List[str]) -> List[float]:\n",
        "        \"\"\"\n",
        "        Runs inference on a batch of images and corresponding captions.\n",
        "        Returns a batch of reward scores.\n",
        "        \"\"\"\n",
        "        if not isinstance(inputs, list) or not all(isinstance(i, PIL.Image.Image) for i in inputs):\n",
        "            raise TypeError(\"Expected 'inputs' to be a list of PIL.Image objects.\")\n",
        "        if not isinstance(captions, list) or not all(isinstance(c, str) for c in captions):\n",
        "            raise TypeError(\"Expected 'captions' to be a list of strings.\")\n",
        "        if len(inputs) != len(captions):\n",
        "            raise ValueError(\"Number of 'inputs' and 'captions' must match.\")\n",
        "\n",
        "        try:\n",
        "            text_tokens = self.tokenizer(captions).to(self.device)\n",
        "\n",
        "            with torch.cuda.amp.autocast():\n",
        "                outputs = self.model(inputs, text_tokens)\n",
        "                image_features, text_features = outputs[\"image_features\"], outputs[\"text_features\"]\n",
        "                return (image_features @ text_features.T).diag() * 100\n",
        "\n",
        "        except Exception as e:\n",
        "            raise InferenceError(f\"Inference failed: {e}\") from e"
      ],
      "metadata": {
        "id": "33IxgoCcTkQ5"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class BaseDiffusionModel(BaseModel):\n",
        "    def __init__(self, model_path: str, offload_to_cpu: bool = False, resolution: int = None, **kwargs):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            model_path (str): Path or repository ID of the diffusion model checkpoint.\n",
        "        \"\"\"\n",
        "        self.seed = 42\n",
        "\n",
        "        self.device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "        self.model_path = model_path\n",
        "        self.offload_to_cpu = offload_to_cpu\n",
        "        self.resolution = resolution\n",
        "        self.kwargs = kwargs\n",
        "\n",
        "        self.diffusion_pipeline = self._get_diffusion_pipeline()\n",
        "        self.load_model()\n",
        "\n",
        "    def _get_diffusion_pipeline(self):\n",
        "        \"\"\" Subclasses should override this to return the correct pipeline. \"\"\"\n",
        "        return DiffusionPipeline\n",
        "\n",
        "    def load_model(self):\n",
        "        try:\n",
        "            self.model = self.diffusion_pipeline.from_pretrained(\n",
        "                self.model_path,\n",
        "                **self.kwargs\n",
        "            ).to(self.device)\n",
        "            if self.offload_to_cpu:\n",
        "                self.model.enable_model_cpu_offload()\n",
        "\n",
        "        except MemoryError as e:\n",
        "            if hasattr(self, \"model\"):\n",
        "                del self.model\n",
        "                torch.cuda.empty_cache()\n",
        "            raise ModelLoadingError(f\"Memory error occurred while loading the model. Consider using a smaller model: {e}\")\n",
        "        except FileNotFoundError as e:\n",
        "            raise ModelLoadingError(f\"Model checkpoint not found at '{self.model_path}'.\") from e\n",
        "        except Exception as e:\n",
        "            raise ModelLoadingError(f\"Failed to load diffusion model: {e}\") from e\n",
        "\n",
        "    def inference(\n",
        "        self, inputs: List[str], captions: Optional[List[str]] = None\n",
        "    ):\n",
        "        \"\"\"\n",
        "        Runs inference on a batch of prompts.\n",
        "        Returns a batch of images corresponding to the prompts.\n",
        "        \"\"\"\n",
        "        if not isinstance(inputs, list) or not all(isinstance(c, str) for c in inputs):\n",
        "            raise TypeError(\"Expected 'inputs' to be a list of strings.\")\n",
        "\n",
        "        try:\n",
        "            # Create one generator per prompt to ensure reproducibility\n",
        "            generators = [\n",
        "                torch.Generator(self.device).manual_seed(self.seed) for _ in range(len(inputs))\n",
        "            ]\n",
        "            if self.resolution:\n",
        "                images = self.model(\n",
        "                    prompt=inputs, generator=generators,\n",
        "                    height=self.resolution, width=self.resolution # use 1:1 aspect ratio\n",
        "                ).images\n",
        "                return images\n",
        "            else:\n",
        "                images = self.model(\n",
        "                    prompt=inputs, generator=generators,\n",
        "                ).images\n",
        "                return images\n",
        "\n",
        "        except Exception as e:\n",
        "            raise InferenceError(f\"Inference failed: {e}\")"
      ],
      "metadata": {
        "id": "kVVBTkx4JaQf"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class StableDiffusionModel(BaseDiffusionModel):\n",
        "    def __init__(self, model_path: str, offload_to_cpu: bool = False, resolution: int = None, **kwargs):\n",
        "        \"\"\"\n",
        "        Note:\n",
        "            model_path (str): Path to the Stable Diffusion model.\n",
        "                              Must include 'stable-diffusion-1', 'stable-diffusion-2', or 'stable-diffusion-3' after '<repo-owner>/'\n",
        "                              for simplicity.\n",
        "        \"\"\"\n",
        "\n",
        "        # Load the model with float16 precision.\n",
        "        # If your GPU supports torch.bfloat16 for lower memory usage with similar precision to FP32,\n",
        "        # consider switching the torch_dtype accordingly.\n",
        "        if \"torch_dtype\" not in kwargs:\n",
        "            kwargs[\"torch_dtype\"] = torch.float16\n",
        "        super().__init__(model_path, offload_to_cpu, resolution, **kwargs)\n",
        "\n",
        "    def _get_diffusion_pipeline(self):\n",
        "        version_tag = self.model_path.split(\"/\")[-1].lower()\n",
        "\n",
        "        if re.search(r'(stable-diffusion-?(v-?|v)?1(?:-\\d+)?)(.*)?$', version_tag):\n",
        "            return StableDiffusionPipeline\n",
        "        elif re.search(r'(stable-diffusion-?(v-?|v)?2(?:-\\d+)?)(.*)?$', version_tag):\n",
        "            return DiffusionPipeline\n",
        "        elif re.search(r'(stable-diffusion-?(v-?|v)?3(?:-\\d+)?)(.*)?$', version_tag):\n",
        "            return StableDiffusion3Pipeline\n",
        "        else:\n",
        "            raise ValueError(\n",
        "                \"Model path must match 'stable-diffusion-1', 'stable-diffusion-v1', 'stable-diffusion-v-1', \"\n",
        "                \"'stable-diffusion-2', 'stable-diffusion-v2', etc.\"\n",
        "            )"
      ],
      "metadata": {
        "id": "QII1xUW_Dv7d"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ModelFactory:\n",
        "    @staticmethod\n",
        "    def create_model(\n",
        "        model_type: str, model_path: str,\n",
        "        **kwargs,\n",
        "    ) -> BaseModel:\n",
        "        \"\"\"\n",
        "        Creates and returns an instance of a model subclass based on the model_type.\n",
        "\n",
        "        Args:\n",
        "            model_type (str): The type of model to create. Supported values are:\n",
        "                - \"hpsv1\": For HPSv1 reward models.\n",
        "                - \"hpsv2\": For HPSv2 reward models.\n",
        "                - \"sd\": For stable diffusion text-to-image models.\n",
        "            model_path (str): The path or repository ID of the model checkpoint.\n",
        "\n",
        "        Returns:\n",
        "            BaseModel: An instance of the requested model.\n",
        "\n",
        "        Raises:\n",
        "            ValueError: If an unsupported model_type is provided.\n",
        "        \"\"\"\n",
        "        if model_type == \"hpsv1\":\n",
        "            return HPSv1Model(model_path)\n",
        "        elif model_type == \"hpsv2\":\n",
        "            return HPSv2Model(model_path)\n",
        "        elif model_type == \"sd\":\n",
        "            return StableDiffusionModel(model_path, **kwargs)\n",
        "        else:\n",
        "            raise ValueError(\"Unsupported model type. Use 'sd' for stable diffusion models or 'hps' for HPS models.\")"
      ],
      "metadata": {
        "id": "ehIBzLG_ieeG"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "5. Dataset Code"
      ],
      "metadata": {
        "id": "2Wq_hTQKfM9f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class DatasetFormatError(Exception):\n",
        "    \"\"\"Raised when the dataset format is incorrect.\"\"\"\n",
        "    pass\n",
        "\n",
        "class DatasetLoadingError(Exception):\n",
        "    \"\"\"Raised when the dataset fails to load properly.\"\"\"\n",
        "    pass"
      ],
      "metadata": {
        "id": "br0iOYEMgiDj"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class BasePromptDataset(Dataset, ABC):\n",
        "    def __init__(self):\n",
        "        try:\n",
        "            self.data = self.load_dataset()\n",
        "        except Exception as e:\n",
        "            raise DatasetLoadingError(f\"Failed to load dataset: {e}\")\n",
        "\n",
        "        if not isinstance(self.data, dict):\n",
        "            raise DatasetFormatError(f\"Expected 'load_dataset()' to return a dictionary, got '{type(self.data)}'.\")\n",
        "\n",
        "        for key, prompts in self.data.items():\n",
        "            if not isinstance(prompts, list) or not all(isinstance(p, str) for p in prompts):\n",
        "                raise DatasetFormatError(f\"Expected a list of strings for category '{key}', but got '{type(prompts)}'\")\n",
        "\n",
        "        # Precompute samples with round-robin ordering\n",
        "        self.samples = self._create_round_robin_samples()\n",
        "\n",
        "    @abstractmethod\n",
        "    def load_dataset(self) -> Dict[str, List[str]]:\n",
        "        \"\"\"To be implemented by subclasses.\"\"\"\n",
        "        pass\n",
        "\n",
        "    def _create_round_robin_samples(self) -> List[Dict[str, str]]:\n",
        "        \"\"\"Ensure fair round-robin interleaving of prompts from all categories.\"\"\"\n",
        "        samples = []\n",
        "        categories = list(self.data.keys())\n",
        "        category_prompts = [self.data[cat] for cat in categories]\n",
        "\n",
        "        if not categories or all(len(prompts) == 0 for prompts in category_prompts):\n",
        "            raise DatasetFormatError(\"Dataset is empty or contains only empty categories.\")\n",
        "\n",
        "        max_length = max(len(prompts) for prompts in category_prompts)\n",
        "\n",
        "        # Round-robin interleaving\n",
        "        for i in range(max_length):\n",
        "            for cat_idx, category in enumerate(categories):\n",
        "                prompts = category_prompts[cat_idx]\n",
        "                if len(prompts) > 0:\n",
        "                    prompt = prompts[i % len(prompts)]  # Cycle back for shorter lists\n",
        "                    samples.append({\"category\": category, \"prompt\": prompt})\n",
        "\n",
        "        return samples\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.samples)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.samples[idx]\n",
        "\n",
        "    def num_categories(self) -> int:\n",
        "        \"\"\"Returns the number of unique categories in the dataset.\"\"\"\n",
        "        return len(self.data)"
      ],
      "metadata": {
        "id": "-aJsW0f8fOR8"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class HPSV2PromptDataset(BasePromptDataset):\n",
        "    def load_dataset(self) -> Dict[str, List[str]]:\n",
        "        all_prompts = hpsv2.benchmark_prompts(\"all\")\n",
        "        return dict(all_prompts.items())"
      ],
      "metadata": {
        "id": "iNuLke0ogt1o"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class DrawBenchPromptDataset(BasePromptDataset):\n",
        "    def load_dataset(self) -> Dict[str, List[str]]:\n",
        "        df = pd.read_csv(\"drawbench_data.csv\")\n",
        "        return df.groupby(\"Category\")[\"Prompts\"].apply(list).to_dict()"
      ],
      "metadata": {
        "id": "rEbS3Tnngw8o"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ImagePromptDataset(Dataset):\n",
        "    def __init__(\n",
        "            self,\n",
        "            image_list: List[PIL.Image], prompt_list: List[Tuple[str, str]],\n",
        "            image_transform_function: callable, text_tokenizer_function: callable = None\n",
        "        ):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            image_list (List[PIL.Image]): List of PIL images.\n",
        "            prompt_list (List[Tuple[str, str]]): List of (category, prompt) tuples.\n",
        "            image_transform_function (callable): Function to transform PIL images.\n",
        "            text_tokenizer_function (callable): Function to tokenize text prompts.\n",
        "        \"\"\"\n",
        "        if len(image_list) == 0 or len(prompt_list) == 0:\n",
        "            raise DatasetFormatError(\"Both image_list and prompt_list must be non-empty.\")\n",
        "        if len(image_list) != len(prompt_list):\n",
        "            raise DatasetFormatError(\"Images and prompts must have the same length.\")\n",
        "\n",
        "        self.images = image_list\n",
        "        self.prompts = prompt_list  # List of (category, prompt)\n",
        "        self.image_transform_function = image_transform_function\n",
        "        self.text_tokenizer_function = text_tokenizer_function\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.images)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        image = self.image_transform_function(self.images[idx])\n",
        "        _, prompt = self.prompts[idx]\n",
        "        if self.text_tokenizer_function is None:\n",
        "            tokens = prompt\n",
        "        else:\n",
        "            tokens = self.text_tokenizer_function(prompt)\n",
        "\n",
        "        return image, tokens"
      ],
      "metadata": {
        "id": "ZkG1-SFKg8-t"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class RoundRobinSampler(torch.utils.data.Sampler):\n",
        "    def __init__(self, dataset: BasePromptDataset):\n",
        "        self.dataset = dataset\n",
        "        self.indices = self._generate_indices()\n",
        "\n",
        "    def _generate_indices(self):\n",
        "        \"\"\"\n",
        "        Assume dataset.data has equal length lists per category.\n",
        "\n",
        "        For each category, create a shuffled list of indices corresponding to that category's samples.\n",
        "        Since BasePromptDataset precomputes samples in round-robin order, we need to map from category + position\n",
        "        to the flat sample index.\n",
        "\n",
        "        In our round-robin samples, the ordering is:\n",
        "        index 0: category1, index 1: category2, ..., index N: category1\n",
        "\n",
        "        Let K = number of categories,\n",
        "        Then the sample index for category j at position i is: i*K + j.\n",
        "        \"\"\"\n",
        "        categories = list(self.dataset.data.keys())\n",
        "        num_per_category = len(next(iter(self.dataset.data.values())))\n",
        "        K = len(categories)\n",
        "\n",
        "        category_indices = {}\n",
        "        for j, cat in enumerate(categories):\n",
        "            indices = [i * K + j for i in range(num_per_category)]\n",
        "            random.shuffle(indices)\n",
        "            category_indices[cat] = indices\n",
        "\n",
        "        ordered_indices = []\n",
        "        for i in range(num_per_category):\n",
        "            for cat in categories:\n",
        "                ordered_indices.append(category_indices[cat][i])\n",
        "        return ordered_indices\n",
        "\n",
        "    def __iter__(self):\n",
        "        return iter(self.indices)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.indices)"
      ],
      "metadata": {
        "id": "4Dm6NzvhiO3E"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class DatasetFactory:\n",
        "    @staticmethod\n",
        "    def create_dataset(\n",
        "        dataset_type: str,\n",
        "        **kwargs,\n",
        "    ) -> Union[BasePromptDataset, ImagePromptDataset]:\n",
        "\n",
        "        if dataset_type == \"drawbench\":\n",
        "            return DrawBenchPromptDataset()\n",
        "        elif dataset_type == \"hps\":\n",
        "            return HPSV2PromptDataset()\n",
        "        elif dataset_type == \"imageandprompt\":\n",
        "            return ImagePromptDataset(**kwargs)\n",
        "        else:\n",
        "            raise ValueError(f\"Unknown dataset type: '{dataset_type}'.\")"
      ],
      "metadata": {
        "id": "xMV2IXqaibKB"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "6. Define Arguments and Utils"
      ],
      "metadata": {
        "id": "vxzEzwrVfOyd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def check_target_model(value):\n",
        "    pattern = r'^[^/]+/(stable-diffusion-?(v-?|v)?[123](?:-\\d+)?)(.*)?$'\n",
        "\n",
        "    if not re.match(pattern, value):\n",
        "        raise argparse.ArgumentTypeError(\n",
        "            \"target_model_name must be in the format '<repo-owner>/stable-diffusion-[1|2|3]', \"\n",
        "            \"'<repo-owner>/stable-diffusion-v[1|2|3]', or '<repo-owner>/stable-diffusion-v-[1|2|3]'.\"\n",
        "        )\n",
        "    return value\n",
        "\n",
        "def check_dataset_name(value):\n",
        "    if value not in ['hps', 'drawbench']:\n",
        "        raise argparse.ArgumentTypeError(\n",
        "            \"dataset_name must be either 'hps' or 'drawbench'.\")\n",
        "    return value\n",
        "\n",
        "def parse_model_args():\n",
        "    parser = argparse.ArgumentParser(\n",
        "        description=\"Argument partser for image generation process.\"\n",
        "    )\n",
        "\n",
        "    # Models group\n",
        "    models = parser.add_argument_group(\"models\")\n",
        "    models.add_argument(\"--target_model_name\", type=check_target_model, required=True,\n",
        "                        help=\"HuggingFace model ID in format <repo-owner>/stable-diffusion-[1|2|3]\")\n",
        "\n",
        "    # Datasets group\n",
        "    datasets = parser.add_argument_group(\"datasets\")\n",
        "    datasets.add_argument(\"--dataset_name\", type=check_dataset_name, required=True,\n",
        "                        help=\"Dataset for generating preliminary images: 'hps' or 'drawbench'\")\n",
        "    datasets.add_argument(\"--num_samples_per_category\", type=int, default=None,\n",
        "                        help=\"Number of text prompts per category (default: 5 for hps, 2 for drawbench)\")\n",
        "    datasets.add_argument(\"--shuffle\", action=\"store_true\",\n",
        "                        help=\"Shuffle prompts prior to sampling (default: False)\")\n",
        "\n",
        "    # Misc group\n",
        "    misc = parser.add_argument_group(\"misc\")\n",
        "    misc.add_argument(\"--inference_batch_size\", type=int, default=4,\n",
        "                        help=\"Batch size for target model inference (default: 4)\")\n",
        "    misc.add_argument(\"--no_save_image_results\", dest=\"save_image_results\", action=\"store_false\",\n",
        "                        help=\"Do not store images, prompts, and reward scores that pass threshold\")\n",
        "    misc.set_defaults(save_image_results=True)\n",
        "\n",
        "    args = parser.parse_args()\n",
        "    if args.num_samples_per_category is None:\n",
        "        if args.dataset_name == \"hps\":\n",
        "            args.num_samples_per_category = 5\n",
        "        else:  # drawbench\n",
        "            args.num_samples_per_category = 2\n",
        "    return args"
      ],
      "metadata": {
        "id": "2e5ywfpbgWdI"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def clear_cuda_memory_and_force_gc(force: bool = False):\n",
        "    \"\"\"\n",
        "    Clears the CUDA memory cache and forces garbage collection if the allocated memory\n",
        "    exceeds a certain threshold or if explicitly forced.\n",
        "\n",
        "    Args:\n",
        "        force (bool): If True, CUDA cache will be cleared and garbage collection\n",
        "                      will be forced regardless of the memory threshold.\n",
        "    \"\"\"\n",
        "\n",
        "    memory_allocated = torch.cuda.max_memory_reserved()\n",
        "    memory_total = torch.cuda.get_device_properties(\"cuda\").total_memory\n",
        "\n",
        "    memory_threshold = memory_total * 0.7\n",
        "    if memory_allocated > memory_threshold or force:\n",
        "        torch.cuda.empty_cache()\n",
        "        gc.collect()"
      ],
      "metadata": {
        "id": "PAMY0Fwuhbt5"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SampledDataset(Dataset):\n",
        "    def __init__(self, prompts):\n",
        "        self.data = [{\"category\": c, \"prompt\": p} for c, p in zip(prompts[\"category\"], prompts[\"prompt\"])]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.data[idx]"
      ],
      "metadata": {
        "id": "guE0Pg4MhkIO"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "7. Generate Base Images"
      ],
      "metadata": {
        "id": "B67ARZTDhpQg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_images(generate_image_args):\n",
        "    print(generate_image_args)\n",
        "    kwargs = {}\n",
        "\n",
        "    if re.search(r'(stable-diffusion-2|v-?2)', generate_image_args.target_model_name):\n",
        "        kwargs = {\n",
        "            \"resolution\": 512,\n",
        "        }\n",
        "    if re.search(r'(stable-diffusion-3|v-?3)', generate_image_args.target_model_name):\n",
        "        kwargs = {\n",
        "            \"resolution\": 512,\n",
        "            \"offload_to_cpu\": True,\n",
        "            \"text_encoder_3\": None,\n",
        "            \"tokenizer_3\": None,\n",
        "            \"token\": \"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\"\n",
        "\n",
        "        }\n",
        "\n",
        "    model = ModelFactory.create_model(\n",
        "        model_type=\"sd\",\n",
        "        model_path=generate_image_args.target_model_name,\n",
        "        **kwargs,\n",
        "    )\n",
        "\n",
        "    dataset = DatasetFactory.create_dataset(\n",
        "        dataset_type=generate_image_args.dataset_name,\n",
        "    )\n",
        "\n",
        "    # Generate twice as many images as the number of samples per category for safety\n",
        "    num_images_to_gen = 2 * generate_image_args.num_samples_per_category * dataset.num_categories()\n",
        "    dataset_loader = DataLoader(\n",
        "        dataset,\n",
        "        batch_size=num_images_to_gen,\n",
        "        sampler=RoundRobinSampler(dataset) if generate_image_args.shuffle else None,\n",
        "    )\n",
        "\n",
        "    prompts = next(iter(dataset_loader))\n",
        "    sampled_dataset = SampledDataset(prompts)\n",
        "    sampled_dataset_loader = DataLoader(sampled_dataset, batch_size=generate_image_args.inference_batch_size, shuffle=False)\n",
        "\n",
        "    final_images = []\n",
        "    final_prompts = []\n",
        "    total_batches = len(sampled_dataset_loader)\n",
        "    pbar = tqdm(total=total_batches, desc=\"Generating images from prompts\")\n",
        "\n",
        "    for batch in sampled_dataset_loader:\n",
        "        prompts = batch[\"prompt\"]\n",
        "        categories = batch[\"category\"]\n",
        "        images = model.inference(inputs=prompts)\n",
        "        final_images.extend(images)\n",
        "        final_prompts.extend([(category, prompt) for category, prompt in zip(categories, prompts)])\n",
        "        pbar.update(1)\n",
        "    pbar.close()\n",
        "\n",
        "    if generate_image_args.save_image_results:\n",
        "        timestamp = datetime.now().strftime(\"%Y-%m-%d-%H-%M-%S\")\n",
        "        output_dir = os.path.join(f\"outputs/{generate_image_args.target_model_name.split('/')[1]}/{generate_image_args.dataset_name}/{timestamp}/\")\n",
        "        os.makedirs(output_dir)\n",
        "\n",
        "        prompts_file = os.path.join(output_dir, \"prompts.txt\")\n",
        "        with open(prompts_file, \"w\") as pf:\n",
        "            for idx, (img, prompt) in enumerate(zip(final_images, final_prompts)):\n",
        "                image_filename = os.path.join(output_dir, f\"image_{idx}.png\")\n",
        "                img.save(image_filename)\n",
        "                pf.write(f\"Image {idx}: {prompt}\\n\")\n",
        "\n",
        "\n",
        "    clear_cuda_memory_and_force_gc(force=True)"
      ],
      "metadata": {
        "id": "UIQNlcqQhqdj"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import argparse\n",
        "import sys\n",
        "\n",
        "sys.argv = [\n",
        "    \"script_name\",  # Placeholder for script name (ignored by argparse)\n",
        "    \"--target_model_name\", \"stabilityai/stable-diffusion-3-medium-diffusers\",\n",
        "    \"--dataset_name\", \"hps\",\n",
        "]\n",
        "\n",
        "args = parse_model_args()\n",
        "generate_images(args)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297,
          "referenced_widgets": [
            "9f98bc2e2217477aa7003918e8f9b319",
            "fbb1d6be963a4993b7fa8c970b221140",
            "d7692de48712479aa9ea3e8dd714f2be",
            "5b7c1a3566644490b1fe0c5d4b01f032",
            "48130d221cf0441fbc477ba7c4db149a",
            "8f54b32085f34cf9820ea408b1e32445",
            "2363dc132d3f4eb487b904d6d1d27bbe",
            "a0faed6f5577489685e5a6b9ad1d395e",
            "9f180b546e1c4920b8175f59f857337e",
            "aa8a521493264f8d98a1d07579e5a493",
            "fc983de7840a48a08cd0549b6344b786",
            "32759be5c6e7480799d2e1b85272e8b6",
            "aa772f701c8b42bdbcd54330b7c35b8e",
            "ef739a9b955c48a9854dc9c296d362a0",
            "fdc3081def0a436d95bb79226156215f",
            "7809096174b04a84aefc806052297411",
            "bae6d27ebeac4330a89d0746405dabe8",
            "cc46b5e284ed4f61b5eab7b72d6ab4f8",
            "75a57aa855b74e479737fd13f0b2d5ef",
            "9052651e2b9944478a45f7349a3d74e3",
            "3f86fc1ebdac48ceac2ff1f97c3b55f6",
            "606f88d809544428987a5d2a51102abc",
            "3b40bb4f107f4d328f820ce58ec67ecb",
            "97a855e118f94779bd7d83bac0a7a2e4",
            "c2070caa349f4ffb9bc309c5a4def34b",
            "ce1454b1515345a4970ba4e4fef85d9d",
            "1ba2fbf9610f4817af714693ec0435c1",
            "6008de7448c74ad98ce6478fa0c20244",
            "51e9d43ecd9f406e8da592cf3913d2aa",
            "a312fe828e194bf981369798a8d83f1a",
            "21467b05c1114967be68d30f86dc5c9b",
            "b158e721242c4b2f921ae16c97169f89",
            "68278a34dd034a73a47b5aacaffe343f"
          ]
        },
        "id": "TVneiSHniC5u",
        "outputId": "003621ed-7a42-41f5-a0af-6eba946280d4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Namespace(target_model_name='stabilityai/stable-diffusion-3-medium-diffusers', dataset_name='hps', num_samples_per_category=5, shuffle=False, inference_batch_size=4, save_image_results=True)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading pipeline components...:   0%|          | 0/7 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9f98bc2e2217477aa7003918e8f9b319"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n",
            "Generating images from prompts:   0%|          | 0/10 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/28 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "32759be5c6e7480799d2e1b85272e8b6"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rGenerating images from prompts:  10%|█         | 1/10 [02:30<22:31, 150.19s/it]"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/28 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3b40bb4f107f4d328f820ce58ec67ecb"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "clear_cuda_memory_and_force_gc(force=True)"
      ],
      "metadata": {
        "id": "GeR7sNiPnwn6"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}